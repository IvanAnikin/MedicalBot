# MedicalBot Development Plan

## Phase 0 ‚Äì Project Setup ‚úÖ COMPLETE

### Repo & Structure ‚úÖ

- [x] Create git repo ‚úÖ
- [x] Create base folders: ‚úÖ
    - [x] `main.py` (FastAPI app entrypoint)
    - [x] `templates/` (for index.html)
    - [x] `static/` (placeholder for later)
    - [x] `app/` package (for organization):
        - [x] `app/audio_manager.py`
        - [x] `app/openai_client.py`
        - [x] `app/state.py` (for global recording state)
- [x] Add `.gitignore` (venv, `__pycache__`, IDE stuff) ‚úÖ

### Environment & Dependencies ‚úÖ

- [x] Create virtual environment ‚úÖ
- [x] Install dependencies: ‚úÖ
    - [x] `fastapi` (0.104.1)
    - [x] `uvicorn[standard]` (0.24.0)
    - [x] `openai` (1.3.8)
    - [x] `sounddevice` (0.4.6)
    - [x] `numpy` (1.24.3)
    - [x] `jinja2` (3.1.2)
    - [x] `python-multipart` (0.0.6)
    - [x] `python-dotenv` (1.0.0)
- [x] Create `requirements.txt` with frozen versions ‚úÖ

### Configuration ‚úÖ

- [x] Configured with `.env` + python-dotenv ‚úÖ
- [x] Defined environment variables: ‚úÖ
    - [x] `OPENAI_API_KEY` (required)
    - [x] `OPENAI_TRANSCRIPTION_MODEL` (default: whisper-1)
    - [x] `OPENAI_CHAT_MODEL` (default: gpt-4o-mini)
    - [x] `APP_PORT` (default: 8000)
- [x] Create `.env.example` with placeholders ‚úÖ
- [x] Created documentation files: SETUP.md, PHASE0_COMPLETE.md, PROJECT_READY.md ‚úÖ

## Phase 1 ‚Äì Global App State & Audio Manager ‚úÖ COMPLETE

### Global Recording State ‚úÖ

- [x] Implement `app/state.py` with: ‚úÖ
  - [x] `recording_active: bool = False`
  - [x] `stop_event: threading.Event`
  - [x] `audio_queue: queue.Queue`
  - [x] `recording_thread: Thread | None`
  - [x] `transcription_thread: Thread | None`
  - [x] `current_transcript: str = ""`
- [x] Provide helper functions to reset/init state ‚úÖ
  - [x] `reset()` - Clear state
  - [x] `set_recording_active()` - Thread-safe flag setter
  - [x] `get_transcript()` - Thread-safe getter
  - [x] `append_transcript()` - Thread-safe appender

### Audio Recording Manager ‚úÖ

- [x] Create `app/audio_manager.py` ‚úÖ
- [x] Implement config constants: ‚úÖ
  - [x] `SAMPLE_RATE = 16000`
  - [x] `CHANNELS = 1`
  - [x] `CHUNK_SIZE = 1024`
- [x] Implement `start_recording_thread(state)`: ‚úÖ
  - [x] Starts background thread (daemon=False)
  - [x] Opens `sounddevice.InputStream` with default input device
  - [x] While `not stop_event.is_set()`: read chunks and push to `audio_queue`
- [x] Implement `stop_recording_thread(state)`: ‚úÖ
  - [x] Signals `stop_event`
  - [x] Joins recording thread with 5 second timeout
- [x] Add exception handling for mic/device errors ‚úÖ

## Phase 2 ‚Äì OpenAI Integration ‚úÖ COMPLETE

### OpenAI Client Helper ‚úÖ

- [x] Create `app/openai_client.py` ‚úÖ
- [x] Initialize OpenAI client using `OPENAI_API_KEY` ‚úÖ
- [x] Implement model helpers: ‚úÖ
  - [x] `get_transcription_model()` - Returns model from env or default
  - [x] `get_chat_model()` - Returns model from env or default
- [x] Implement `start_transcription_worker(state)`: ‚úÖ
  - [x] Runs in own background thread
  - [x] Collects audio chunks from `audio_queue`
  - [x] Sends to OpenAI Whisper API for transcription
  - [x] Updates `current_transcript` with results
  - [x] Handles graceful finalization

### Report Generation ‚úÖ

- [x] Implement `generate_structured_report(transcript: str) -> str`: ‚úÖ
  - [x] Define system prompt with medical sections:
    - [x] Patient Identification
    - [x] Chief Complaint / Reason for Visit
    - [x] History of Present Illness
    - [x] Past Medical History / Allergies / Medications
    - [x] Objective Findings
    - [x] Assessment
    - [x] Plan
  - [x] Mark missing info as "Not mentioned in transcript"
  - [x] Call OpenAI chat model with low temperature (0.3)
  - [x] Handle exceptions with clear error messages

## Phase 3 ‚Äì FastAPI Endpoints ‚úÖ COMPLETE

### App Initialization ‚úÖ

- [x] Create FastAPI instance in `main.py` ‚úÖ
- [x] Configure Jinja2Templates ‚úÖ
- [x] Mount `/static` directory ‚úÖ
- [x] Load environment variables from `.env` ‚úÖ

### Endpoints ‚úÖ

All 6 endpoints implemented and working:

| Method | Path | Description | Status |
|--------|------|-------------|--------|
| `GET` | `/` | Return index.html | ‚úÖ |
| `POST` | `/start_recording` | Start recording; return 409 if already active | ‚úÖ |
| `POST` | `/stop_recording` | Stop recording; return transcript | ‚úÖ |
| `GET` | `/transcript` | Return recording status and current transcript | ‚úÖ |
| `POST` | `/generate_report` | Generate structured report from transcript | ‚úÖ |
| `POST` | `/reset_session` | Clear session state | ‚úÖ |

## Phase 4 ‚Äì Frontend (index.html) ‚úÖ COMPLETE

### Layout ‚úÖ

- [x] Header: app name + status pill ‚úÖ
- [x] Main (2 columns): ‚úÖ
  - [x] **Left**: Structured report card with textarea
  - [x] **Right**: Controls card + Transcript card

### Styling ‚úÖ

- [x] Dark mode with CSS variables ‚úÖ
  - [x] `--bg`, `--card`, `--text`, `--accent`, `--danger`
- [x] Flexbox layout (2 columns desktop, stacked mobile) ‚úÖ
- [x] Rounded cards with soft shadows ‚úÖ
- [x] Pill-shaped buttons ‚úÖ

### Components ‚úÖ

- [x] **Report Card**: textarea #report with helper text ‚úÖ
- [x] **Controls Card**: Start, Stop, Generate, Clear buttons + status pill + error banner ‚úÖ
- [x] **Transcript Card**: textarea #transcript with helper text ‚úÖ

## Phase 5 ‚Äì Frontend JS Logic ‚úÖ COMPLETE

### Helper Functions ‚úÖ

- [x] `setStatus(text, type)` ‚Äì update header pill with status ‚úÖ
- [x] `setRecordingState(isRecording)` ‚Äì toggle button states ‚úÖ
- [x] `setError(message)` / `clearError()` ‚Äì manage error banner ‚úÖ
- [x] `setLoading(on, label)` ‚Äì show processing indicator ‚úÖ

### Recording Flow ‚úÖ

- [x] `startRecording()`: POST `/start_recording`, start polling `/transcript` ‚úÖ
- [x] `stopRecording()`: POST `/stop_recording`, update transcript display ‚úÖ
- [x] `pollTranscript()`: setInterval fetch to keep transcript updated ‚úÖ
- [x] `generateReport()`: POST `/generate_report`, display report ‚úÖ
- [x] `clearAll()`: clear textareas and call `/reset_session` ‚úÖ

### Button Wiring ‚úÖ

- [x] startBtn ‚Üí `startRecording()` ‚úÖ
- [x] stopBtn ‚Üí `stopRecording()` ‚úÖ
- [x] generateBtn ‚Üí `generateReport()` ‚úÖ
- [x] clearBtn ‚Üí `clearAll()` ‚úÖ

## Phase 6 ‚Äì Testing & Integration Testing ‚è≥ IN PROGRESS

### Pre-Testing Checklist

- [x] Setup verification complete ‚úÖ
- [x] All dependencies installed ‚úÖ
- [x] All Python code compiles ‚úÖ
- [x] Configuration files ready ‚úÖ
- [ ] API key configured (‚ö†Ô∏è TODO: Add your OPENAI_API_KEY to .env)

### Unit/Integration Tests

- [ ] Test state management (threading, locking)
- [ ] Test audio manager (device detection, error handling)
- [ ] Test OpenAI client (API connectivity, error handling)
- [ ] Test FastAPI routes (all 6 endpoints)
- [ ] Test frontend JS (button clicks, polling, error display)

### Functional Tests

- [ ] Start server, UI loads at http://localhost:8000
- [ ] Click Start button, verify recording state changes
- [ ] Speak into microphone ~30 seconds
- [ ] Click Stop button, verify transcript appears
- [ ] Click Generate Report, verify structured output
- [ ] Test with ~1‚Äì2 minute dictation
- [ ] Clear All button clears both textareas

### Error Scenario Tests

- [ ] Start without API key ‚Üí verify error message
- [ ] No microphone connected ‚Üí verify graceful error
- [ ] Stop without starting ‚Üí verify proper response
- [ ] Generate report without transcript ‚Üí verify error
- [ ] Rapid start/stop clicks ‚Üí verify thread safety

### Medical Output Validation

- [ ] Test with realistic patient visit dictation
- [ ] Verify all sections present in report:
  - Patient Identification
  - Chief Complaint
  - History of Present Illness
  - Past Medical History/Allergies/Medications
  - Objective Findings
  - Assessment
  - Plan
- [ ] Confirm "Not mentioned in transcript" for missing sections
- [ ] Verify medical language is appropriate and concise

### Documentation & Polish

- [ ] Update README.md with:
  - Architecture overview
  - Setup & run instructions
  - Workflow explanation
  - Privacy note (local app, OpenAI calls only)
- [ ] Verify all docs are up-to-date
- [ ] Test on different browsers (Chrome, Firefox, Safari)
- [ ] Verify responsive design on mobile

## Phase 7 ‚Äì Backlog (Post-v1)

- Add patient metadata form (name, DOB, visit date)
- Add report templates (GP, internal, nursing)
- Add session persistence (SQLite)
- Replace polling with WebSocket
- Add password/PIN gate
- Add audio file upload support
- Add report editing/review UI
- Add multi-user session support

---

## üß™ Testing Guide - How to Test the App

### Prerequisites Before Testing

1. **Add Your API Key**
   ```bash
   # Edit .env file
   nano .env
   
   # Update:
   OPENAI_API_KEY=sk-your-actual-key-here
   ```

2. **Verify Setup**
   ```bash
   bash verify_setup.sh
   ```

### Quick Start Test (2 minutes)

**Terminal 1: Start the server**
```bash
cd /Users/ivananikin/Documents/MedicalBot
source venv/bin/activate
python main.py
```

Expected output:
```
INFO:     Uvicorn running on http://0.0.0.0:8000
INFO:     Application startup complete
```

**Terminal 2: Test endpoints**
```bash
# Test 1: UI loads
curl http://localhost:8000/

# Test 2: Get initial state
curl http://localhost:8000/transcript

# Test 3: Start recording
curl -X POST http://localhost:8000/start_recording

# Test 4: Stop recording (speak into mic during this time!)
sleep 5
curl -X POST http://localhost:8000/stop_recording
```

### Full Manual Test (5-10 minutes)

1. **Start server**
   ```bash
   cd /Users/ivananikin/Documents/MedicalBot
   source venv/bin/activate
   python main.py
   ```

2. **Open browser**
   - Navigate to: http://localhost:8000/
   - Should see: Dark-mode UI with 2 columns

3. **Test Recording Flow**
   - Status should show "Ready" (green)
   - Click **Start** button
   - Status should change to "Recording" (red, pulsing)
   - Speak clearly for 30 seconds to 2 minutes
   - Example: "Patient reports fever for 3 days, temperature 101.5. Throat pain, mild cough. No prior medical history. Allergic to Penicillin. Currently on no medications. Vital signs: BP 120/80, HR 92, RR 16. Physical exam shows red throat. No lymphadenopathy. Assessment: Likely viral pharyngitis. Plan: Rest, fluids, over-the-counter pain relievers, follow up if symptoms worsen."
   - Click **Stop** button
   - Transcript should appear in right textarea

4. **Test Report Generation**
   - Click **Generate Report** button (should be disabled while recording)
   - Loading indicator appears briefly
   - Structured report appears in left textarea with sections:
     - Patient Identification
     - Chief Complaint / Reason for Visit
     - History of Present Illness
     - Past Medical History / Allergies / Medications
     - Objective Findings
     - Assessment
     - Plan

5. **Test Error Handling**
   - Click **Stop** without clicking **Start** ‚Üí Should return empty/error
   - Click **Generate Report** without transcript ‚Üí Should show error
   - Close browser & reopen ‚Üí Should reset state

6. **Test Clear All**
   - Click **Clear All** button
   - Both textareas should empty
   - Status should return to "Ready"

### Automated Testing (via curl)

**Test all endpoints without mic:**

```bash
#!/bin/bash
# Run from Terminal 2 while server is running

# Test 1: Get UI
echo "Test 1: GET /"
curl -s http://localhost:8000/ | head -20

# Test 2: Get initial state
echo -e "\nTest 2: GET /transcript"
curl -s http://localhost:8000/transcript | python -m json.tool

# Test 3: Try to generate report without transcript
echo -e "\nTest 3: POST /generate_report (should fail)"
curl -s -X POST http://localhost:8000/generate_report \
  -H "Content-Type: application/json" \
  -d '{"transcript":""}' | python -m json.tool

# Test 4: Generate report with sample text
echo -e "\nTest 4: POST /generate_report (with text)"
curl -s -X POST http://localhost:8000/generate_report \
  -H "Content-Type: application/json" \
  -d '{"transcript":"Patient John Doe, age 45, came in with chest pain. Temperature 98.6. BP 120/80. Allergic to aspirin. No medications. Exam shows clear lungs. ECG normal. Assessment: Likely anxiety. Plan: Stress management, follow up in 1 week."}' | python -m json.tool

# Test 5: Reset session
echo -e "\nTest 5: POST /reset_session"
curl -s -X POST http://localhost:8000/reset_session | python -m json.tool
```

### Browser DevTools Testing

1. **Open DevTools** (F12 or Cmd+Option+I)
2. **Go to Network tab**
3. Click buttons and watch network requests:
   - **Start** ‚Üí POST /start_recording
   - **Stop** ‚Üí POST /stop_recording
   - **Generate** ‚Üí POST /generate_report
   - Polling ‚Üí GET /transcript (every 500ms during recording)

4. **Go to Console tab**
   - Should see: "MedicalBot UI initialized"
   - Click buttons and watch console for any errors

### Testing Without Microphone

If you don't have a working microphone, you can still test the UI:

```bash
# Test the endpoints with curl commands above
# Test the UI loads and buttons work (without actual recording)
# Test error handling for missing transcript
```

### Testing API Key Issues

```bash
# Test 1: Remove API key
nano .env
# Comment out: OPENAI_API_KEY

# Try to start recording ‚Üí should fail with error message

# Test 2: Invalid API key
OPENAI_API_KEY=sk-invalid python main.py
# Try to generate report ‚Üí should show API error
```

### Stress Testing (Advanced)

```bash
# Simulate multiple rapid requests
for i in {1..10}; do
  curl -s http://localhost:8000/transcript | python -m json.tool
  sleep 0.1
done

# Simulate quick start/stop cycles
curl -s -X POST http://localhost:8000/start_recording
sleep 1
curl -s -X POST http://localhost:8000/stop_recording
sleep 1
curl -s -X POST http://localhost:8000/start_recording
sleep 1
curl -s -X POST http://localhost:8000/stop_recording
```

### Expected Outputs

**GET /transcript (before recording)**
```json
{
  "recording": false,
  "transcript": ""
}
```

**POST /start_recording (success)**
```json
{
  "status": "recording_started"
}
```

**POST /stop_recording (with audio)**
```json
{
  "status": "recording_stopped",
  "transcript": "Patient reported..."
}
```

**POST /generate_report (success)**
```json
{
  "report": "STRUCTURED MEDICAL REPORT\n\nPatient Identification: Not mentioned in transcript\n\nChief Complaint / Reason for Visit: Patient reported chest pain...\n\n..."
}
```

### Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| `ConnectionRefusedError` | Server not running - start with `python main.py` |
| `OPENAI_API_KEY not set` | Add key to `.env` file |
| `Invalid API key` | Check key is correct, not expired |
| `Microphone not found` | Check system audio settings, run `sounddevice.query_devices()` |
| `Port 8000 already in use` | Use different port: `APP_PORT=8001 python main.py` |
| `No transcript appears` | Mic may not be detected, check console for errors |
| `Report generation fails` | Check API key, check OpenAI account quota |

### Performance Testing

- **Recording latency**: Should capture audio with no lag
- **Transcription time**: Depends on audio length & API, typically 10-30 seconds
- **Report generation**: Typically 5-15 seconds
- **UI responsiveness**: Should update in real-time while polling

### Success Criteria

‚úÖ All 6 endpoints return correct status codes
‚úÖ Recording thread starts/stops gracefully
‚úÖ Transcript updates in real-time
‚úÖ Report generates with all medical sections
‚úÖ Error messages are clear and helpful
‚úÖ UI is responsive and intuitive
‚úÖ No crashes or unhandled exceptions

---

**Ready to test?** Start with: `python main.py` then visit http://localhost:8000/

