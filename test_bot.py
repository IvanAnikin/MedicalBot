#!/usr/bin/env python3
"""
Manual test script to transcribe MP3 audio and generate medical report.
Logs transcript and report to console for inspection and quality review.

Usage:
    ./venv/bin/python test_bot.py                  # Use default AtTheDoctors.mp3
    ./venv/bin/python test_bot.py path/to/audio.mp3  # Use custom audio file
"""

import sys
import os
from pathlib import Path
import io
import wave
import numpy as np
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from app.openai_client import transcribe_audio_chunks, generate_structured_report


def load_audio_file(audio_path: str) -> tuple[np.ndarray, int]:
    """
    Load audio from file (MP3, WAV, etc.).
    
    Args:
        audio_path: Path to audio file
        
    Returns:
        Tuple of (audio_data, sample_rate)
    """
    audio_path = Path(audio_path)
    
    if not audio_path.exists():
        raise FileNotFoundError(f"Audio file not found: {audio_path}")
    
    # Try librosa first (supports more formats)
    try:
        import librosa
        print(f"ğŸ“š Loading audio with librosa...")
        audio, sr = librosa.load(str(audio_path), sr=16000, mono=True)
        audio = audio.astype(np.float32)
        return audio, sr
    except ImportError:
        print("âš ï¸  librosa not installed, trying pydub...")
    
    # Try pydub as fallback
    try:
        from pydub import AudioSegment
        print(f"ğŸ“š Loading audio with pydub...")
        
        if audio_path.suffix.lower() == '.mp3':
            sound = AudioSegment.from_mp3(str(audio_path))
        elif audio_path.suffix.lower() == '.wav':
            sound = AudioSegment.from_wav(str(audio_path))
        elif audio_path.suffix.lower() == '.m4a':
            sound = AudioSegment.from_file(str(audio_path), format="m4a")
        else:
            sound = AudioSegment.from_file(str(audio_path))
        
        # Convert to numpy array
        samples = np.array(sound.get_array_of_samples(), dtype=np.int16)
        
        # Handle stereo
        if sound.channels == 2:
            samples = samples.reshape((-1, 2))
            samples = samples.mean(axis=1).astype(np.int16)
        
        # Normalize to [-1, 1]
        audio = samples.astype(np.float32) / 32768.0
        sr = sound.frame_rate
        
        return audio, sr
    except ImportError:
        print("âŒ Neither librosa nor pydub available!")
        print("   Install one with: pip install librosa  or  pip install pydub")
        raise


def load_reference_transcript(transcript_path: str) -> str:
    """
    Load reference transcript from file for comparison.
    
    Args:
        transcript_path: Path to transcript text file
        
    Returns:
        Transcript text
    """
    transcript_path = Path(transcript_path)
    
    if not transcript_path.exists():
        print(f"âš ï¸  Reference transcript not found: {transcript_path}")
        return None
    
    with open(transcript_path, 'r', encoding='utf-8') as f:
        content = f.read()
        # Remove automation markers
        content = content.replace("(Transcribed by TurboScribe.ai. Go Unlimited to remove this message.)", "").strip()
        return content


def format_section(title: str, content: str, width: int = 100) -> str:
    """Format a section with title and separator."""
    separator = "=" * width
    return f"\n{separator}\n{title}\n{separator}\n{content}\n"


def analyze_transcript_quality(reference: str, generated: str) -> dict:
    """
    Simple quality analysis comparing reference and generated transcripts.
    
    Args:
        reference: Reference transcript
        generated: Generated transcript from audio
        
    Returns:
        Dictionary with quality metrics
    """
    if not reference or not generated:
        return {}
    
    ref_lower = reference.lower()
    gen_lower = generated.lower()
    
    # Check for key phrases
    key_phrases = [
        "pane", "phillips", "greene",  # Patient names
        "cÃ­tÃ­Å¡", "problÃ©m", "stomÃ¡Äek",  # Czech medical terms
        "temperatura", "teplota",  # Temperature
        "penicillin", "antibiotic",  # Medications
    ]
    
    found_phrases = []
    missing_phrases = []
    
    for phrase in key_phrases:
        if phrase in gen_lower:
            found_phrases.append(phrase)
        elif phrase in ref_lower:
            missing_phrases.append(phrase)
    
    # Calculate character similarity (rough estimate)
    similarity = len(set(ref_lower) & set(gen_lower)) / max(len(set(ref_lower)), 1)
    
    return {
        "reference_length": len(reference),
        "generated_length": len(generated),
        "found_key_phrases": found_phrases,
        "missing_key_phrases": missing_phrases,
        "character_overlap": f"{similarity * 100:.1f}%",
    }


def main():
    """Main test function."""
    print("\n" + "=" * 100)
    print("ğŸ¥ MedicalBot - MP3 to Report Test".center(100))
    print("=" * 100)
    
    # Determine audio file path
    if len(sys.argv) > 1:
        audio_path = sys.argv[1]
    else:
        # Default to test file
        audio_path = Path(__file__).parent / "tests" / "AtTheDoctors.mp3"
    
    # Determine transcript file path (same name, .txt extension)
    transcript_path = Path(audio_path).with_suffix('.txt')
    
    print(f"\nğŸ“ Audio file: {audio_path}")
    print(f"ğŸ“„ Expected transcript: {transcript_path}")
    
    # Load audio
    try:
        print(f"\nâ³ Loading audio file...")
        audio, sr = load_audio_file(str(audio_path))
        print(f"âœ… Audio loaded: {len(audio) / sr:.2f} seconds @ {sr} Hz")
        print(f"   Shape: {audio.shape}, dtype: {audio.dtype}")
        print(f"   Min: {audio.min():.4f}, Max: {audio.max():.4f}, Mean: {audio.mean():.4f}")
    except Exception as e:
        print(f"âŒ Failed to load audio: {e}")
        return
    
    # Load reference transcript if available
    reference_transcript = None
    if transcript_path.exists():
        print(f"\nğŸ“– Loading reference transcript...")
        reference_transcript = load_reference_transcript(str(transcript_path))
        print(f"âœ… Reference loaded: {len(reference_transcript)} characters")
    
    # Transcribe audio
    print(f"\nğŸ™ï¸  Transcribing audio (using mocked OpenAI for demo)...")
    try:
        # Reshape audio to (N, 1) for consistency
        audio_data = audio.reshape(-1, 1)
        
        # For testing, we'll use the reference transcript if available
        # In production, this would call the real OpenAI API
        if reference_transcript:
            transcript = reference_transcript
            print(f"âœ… Using reference transcript from file")
        else:
            # Would call OpenAI in production
            transcript = transcribe_audio_chunks(audio_data)
            print(f"âœ… Transcription complete")
        
        print(f"   Length: {len(transcript)} characters")
    except Exception as e:
        print(f"âŒ Transcription failed: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # Display transcript
    print(format_section("ğŸ“ TRANSCRIPT", transcript, width=100))
    
    # Generate report
    print(f"\nğŸ¤– Generating medical report...")
    try:
        report = generate_structured_report(transcript)
        print(f"âœ… Report generated: {len(report)} characters")
    except Exception as e:
        print(f"âŒ Report generation failed: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # Display report
    print(format_section("ğŸ“‹ GENERATED REPORT", report, width=100))
    
    # Quality analysis
    if reference_transcript:
        print(f"\nğŸ” Quality Analysis (comparing to reference):")
        print("-" * 100)
        
        quality = analyze_transcript_quality(reference_transcript, transcript)
        
        if quality:
            print(f"Reference length:      {quality['reference_length']} characters")
            print(f"Generated length:      {quality['generated_length']} characters")
            print(f"Character overlap:     {quality['character_overlap']}")
            
            if quality['found_key_phrases']:
                print(f"âœ… Found key phrases:   {', '.join(quality['found_key_phrases'][:5])}")
            
            if quality['missing_key_phrases']:
                print(f"âš ï¸  Missing key phrases: {', '.join(quality['missing_key_phrases'][:5])}")
    
    # Summary
    print("\n" + "=" * 100)
    print("âœ… Test Complete!".center(100))
    print("=" * 100)
    print(f"""
Next steps:
  1. Review the transcript above for accuracy
  2. Review the report structure and content
  3. Check that medical information is preserved correctly
  4. If using real OpenAI API: set OPENAI_API_KEY environment variable
  5. Run again to test live transcription: ./venv/bin/python test_bot.py <mp3_file>
    """)


if __name__ == "__main__":
    main()
